Kashi Interview Questions - Comprehensive Answers & Context Questions

1. If JS is Async, How to Make it Sync and Why?

Answer:

JavaScript is single-threaded but supports asynchronous operations. Sometimes we need to make async operations behave synchronously.

Methods to Make Async Code Synchronous:

1. Using async/await (Recommended):

async function fetchData() {
  try {
    const response = await fetch('https://api.example.com/data');
    const data = await response.json();
    return data;
  } catch (error) {
    console.error('Error:', error);
  }
}

// Usage
async function main() {
  const result = await fetchData(); // Waits for completion
  console.log(result); // Executes after fetchData completes
}

2. Using Promises with .then():

function fetchDataSync() {
  return fetch('https://api.example.com/data')
    .then(response => response.json())
    .then(data => {
      console.log(data);
      return data;
    })
    .catch(error => console.error('Error:', error));
}

3. Using Promise.all() for Multiple Operations:

async function fetchMultipleData() {
  const [users, posts, comments] = await Promise.all([
    fetch('/api/users').then(r => r.json()),
    fetch('/api/posts').then(r => r.json()),
    fetch('/api/comments').then(r => r.json())
  ]);
  
  return { users, posts, comments };
}

4. Sequential Processing with for...of:

async function processSequentially(urls) {
  const results = [];
  
  for (const url of urls) {
    const response = await fetch(url);
    const data = await response.json();
    results.push(data);
  }
  
  return results;
}

Why Make Async Code Synchronous?

1. Data Dependencies:
   - When subsequent operations depend on previous results
   - Example: Need user ID before fetching user posts

2. Sequential Processing:
   - Processing items one by one in order
   - Rate limiting API calls

3. Error Handling:
   - Easier error handling and debugging
   - Clear execution flow

4. Business Logic Requirements:
   - Payment processing must complete before order confirmation
   - Authentication before accessing protected resources

Important Notes:
   - async/await doesn't make JavaScript truly synchronous
   - It makes asynchronous code appear synchronous
   - The event loop continues running
   - Non-blocking for other operations

Context Questions:

1. "What's the difference between async/await and Promise.then() in terms of error handling?"
2. "How do you handle race conditions when making async code synchronous?"
3. "When would you use Promise.all() vs Promise.allSettled() for multiple async operations?"
4. "How do you implement timeout handling with async/await?"
5. "What are the performance implications of making async code synchronous?"
6. "How do you handle cancellation of async operations in JavaScript?"
7. "What's the difference between sequential and parallel async processing?"

---

2. How JS Handles 1000 API Requests Simultaneously?

Answer:

This is an excellent question about JavaScript's concurrency model. JavaScript handles multiple API requests efficiently despite being single-threaded through the Event Loop and Web APIs.

How It Works:

1. Single-Threaded Main Thread:
   - JavaScript execution happens on one main thread
   - Only one piece of JavaScript code executes at a time
   - But I/O operations (like API calls) are non-blocking

2. Web APIs & Browser Environment:

// When you make 1000 API calls:
const promises = [];
for (let i = 0; i < 1000; i++) {
  promises.push(fetch(`https://api.example.com/data/${i}`));
}

// All 1000 requests are initiated immediately
Promise.all(promises)
  .then(responses => {
    console.log('All 1000 requests completed!');
  });

3. The Process Breakdown:

Step 1: Request Initiation (Synchronous)
// Main thread executes this synchronously
fetch('https://api.example.com/data/1'); // Request 1 initiated
fetch('https://api.example.com/data/2'); // Request 2 initiated
fetch('https://api.example.com/data/3'); // Request 3 initiated
// ... 1000 requests initiated rapidly

Step 2: Delegation to Web APIs
   - Each fetch() call is immediately handed off to browser's Web APIs
   - Network requests are handled by the browser's networking layer
   - Main JavaScript thread continues executing (non-blocking)

Step 3: Concurrent Network Operations
   - Browser can handle multiple network connections simultaneously
   - Typical browsers support 6-8 concurrent connections per domain
   - Requests are queued and processed as connections become available

Step 4: Event Loop & Callback Queue
// As responses arrive, callbacks are queued
fetch('https://api.example.com/data/1')
  .then(response => {
    // This callback goes to microtask queue when response arrives
    console.log('Request 1 completed');
  });

Visual Representation:

Main Thread:          Web APIs:              Event Loop:
┌─────────────┐      ┌──────────────┐       ┌─────────────┐
│ fetch(url1) │────→ │ HTTP Request │       │ Callback    │
│ fetch(url2) │────→ │ HTTP Request │       │ Queue       │
│ fetch(url3) │────→ │ HTTP Request │       │             │
│     ...     │      │     ...      │       │ ┌─────────┐ │
│fetch(url1000)│──→  │ HTTP Request │       │ │Response1││
└─────────────┘      └──────────────┘       │ │Response2││
                                            │ │Response3││
                                            │ │   ...   ││
                                            │ └─────────┘ │
                                            └─────────────┘

Key Points:

1. Concurrency vs Parallelism:
   - JavaScript: Concurrent (appears simultaneous)
   - Network layer: Parallel (actually simultaneous)

2. Browser Limitations:
// Browser limits concurrent connections
// Typically 6-8 per domain, 256 total across all domains
const batchSize = 6;
const batches = [];

for (let i = 0; i < 1000; i += batchSize) {
  batches.push(urls.slice(i, i + batchSize));
}

// Process in batches to respect browser limits
for (const batch of batches) {
  await Promise.all(batch.map(url => fetch(url)));
}

3. Memory and Performance Considerations:
// For 1000 requests, consider streaming or pagination
async function fetchInBatches(urls, batchSize = 10) {
  const results = [];
  
  for (let i = 0; i < urls.length; i += batchSize) {
    const batch = urls.slice(i, i + batchSize);
    const batchResults = await Promise.all(
      batch.map(url => fetch(url).then(r => r.json()))
    );
    results.push(...batchResults);
    
    // Optional: Add delay to prevent overwhelming the server
    await new Promise(resolve => setTimeout(resolve, 100));
  }
  
  return results;
}

4. Error Handling for Multiple Requests:
async function fetchWithErrorHandling(urls) {
  const results = await Promise.allSettled(
    urls.map(async url => {
      try {
        const response = await fetch(url);
        return await response.json();
      } catch (error) {
        return { error: error.message, url };
      }
    })
  );
  
  const successful = results.filter(r => r.status === 'fulfilled');
  const failed = results.filter(r => r.status === 'rejected');
  
  return { successful, failed };
}

Summary:
JavaScript can handle 1000 API requests "simultaneously" because:
   - Request initiation is fast and non-blocking
   - Network operations are handled by browser Web APIs (outside main thread)
   - Event loop efficiently manages response callbacks
   - Browser networking layer handles actual parallel connections
   - Main thread remains free to process responses as they arrive

The key insight is that JavaScript delegates I/O operations to the browser environment, allowing the single thread to remain responsive while multiple network operations happen concurrently.

Context Questions:

1. "What are the browser connection limits and how do they affect concurrent requests?"
2. "How does the event loop prioritize different types of callbacks?"
3. "What's the difference between microtask queue and macrotask queue in JavaScript?"
4. "How do you implement request queuing when exceeding browser connection limits?"
5. "What are the memory implications of handling thousands of concurrent requests?"
6. "How do you handle request timeouts and retries in a high-concurrency scenario?"
7. "What's the difference between Promise.all() and Promise.allSettled() for error handling?"

---

3. How Node.js Express Handles 1000 API Requests?

Answer:

Node.js Express can handle thousands of concurrent API requests efficiently through its event-driven, non-blocking I/O architecture. Here's how it works:

Node.js Architecture for Handling Multiple Requests:

1. Event Loop (Single Thread):
   - Main thread runs the event loop
   - Handles I/O operations asynchronously
   - Delegates CPU-intensive tasks to thread pool
   - Non-blocking by design

2. libuv Thread Pool:
   - Background thread pool (default 4 threads)
   - Handles file system operations, DNS lookups, some crypto operations
   - CPU-intensive tasks are offloaded here

3. V8 Engine:
   - Executes JavaScript code
   - Optimizes code execution
   - Manages memory and garbage collection

How Express Handles 1000 Concurrent Requests:

Step 1: Request Reception
const express = require('express');
const app = express();

// This endpoint can handle thousands of concurrent requests
app.get('/api/data/:id', async (req, res) => {
  try {
    // Non-blocking database call
    const data = await database.findById(req.params.id);
    res.json(data);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.listen(3000, () => {
  console.log('Server running on port 3000');
});

Step 2: Event Loop Processing
// When 1000 requests hit simultaneously:
// 1. Each request creates an event in the event queue
// 2. Event loop processes them one by one (very fast)
// 3. I/O operations (DB calls, API calls) are non-blocking
// 4. Callbacks are queued when I/O completes

// Example of non-blocking operations:
app.get('/api/users', async (req, res) => {
  // These operations don't block the event loop
  const [users, posts, comments] = await Promise.all([
    database.getUsers(),     // Non-blocking DB call
    database.getPosts(),     // Non-blocking DB call  
    database.getComments()   // Non-blocking DB call
  ]);
  
  res.json({ users, posts, comments });
});

Step 3: Concurrent Processing Example
const express = require('express');
const app = express();

// Simulate handling 1000 requests
app.get('/api/process/:id', async (req, res) => {
  const startTime = Date.now();
  
  // Simulate async work (database query, API call, etc.)
  await new Promise(resolve => setTimeout(resolve, 100));
  
  const processingTime = Date.now() - startTime;
  
  res.json({
    id: req.params.id,
    processingTime,
    timestamp: new Date().toISOString(),
    message: `Request ${req.params.id} processed successfully`
  });
});

// Load testing script to send 1000 requests
async function loadTest() {
  const promises = [];
  
  for (let i = 1; i <= 1000; i++) {
    promises.push(
      fetch(`http://localhost:3000/api/process/${i}`)
        .then(res => res.json())
    );
  }
  
  const results = await Promise.all(promises);
  console.log(`Processed ${results.length} requests successfully`);
}

Performance Optimizations for High Concurrency:

1. Connection Pooling:
const mysql = require('mysql2/promise');

// Create connection pool to handle multiple DB connections
const pool = mysql.createPool({
  host: 'localhost',
  user: 'user',
  password: 'password',
  database: 'mydb',
  waitForConnections: true,
  connectionLimit: 10,        // Max 10 concurrent connections
  queueLimit: 0
});

app.get('/api/users', async (req, res) => {
  try {
    const [rows] = await pool.execute('SELECT * FROM users');
    res.json(rows);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

2. Clustering for CPU-Intensive Tasks:
const cluster = require('cluster');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
  console.log(`Master ${process.pid} is running`);
  
  // Fork workers equal to CPU cores
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }
  
  cluster.on('exit', (worker, code, signal) => {
    console.log(`Worker ${worker.process.pid} died`);
    cluster.fork(); // Restart worker
  });
} else {
  // Workers can share any TCP port
  const app = express();
  
  app.get('/api/cpu-intensive', (req, res) => {
    // CPU-intensive operation
    let result = 0;
    for (let i = 0; i < 1000000; i++) {
      result += Math.random();
    }
    res.json({ result, worker: process.pid });
  });
  
  app.listen(3000, () => {
    console.log(`Worker ${process.pid} started`);
  });
}

3. Caching for Frequently Accessed Data:
const NodeCache = require('node-cache');
const cache = new NodeCache({ stdTTL: 600 }); // 10 minutes TTL

app.get('/api/cached-data/:id', async (req, res) => {
  const { id } = req.params;
  
  // Check cache first
  const cachedData = cache.get(`data_${id}`);
  if (cachedData) {
    return res.json({ data: cachedData, fromCache: true });
  }
  
  // Fetch from database if not cached
  const data = await database.findById(id);
  
  // Store in cache
  cache.set(`data_${id}`, data);
  
  res.json({ data, fromCache: false });
});

4. Request Rate Limiting:
const rateLimit = require('express-rate-limit');

// Limit each IP to 100 requests per 15 minutes
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100, // limit each IP to 100 requests per windowMs
  message: 'Too many requests from this IP'
});

app.use('/api/', limiter);

5. Streaming for Large Responses:
const fs = require('fs');

app.get('/api/large-data', (req, res) => {
  res.setHeader('Content-Type', 'application/json');
  
  // Stream large data instead of loading into memory
  const readStream = fs.createReadStream('large-data.json');
  readStream.pipe(res);
});

Memory Management for High Concurrency:

1. Monitoring Memory Usage:
app.get('/api/health', (req, res) => {
  const memoryUsage = process.memoryUsage();
  const cpuUsage = process.cpuUsage();
  
  res.json({
    memory: {
      rss: `${Math.round(memoryUsage.rss / 1024 / 1024)} MB`,
      heapTotal: `${Math.round(memoryUsage.heapTotal / 1024 / 1024)} MB`,
      heapUsed: `${Math.round(memoryUsage.heapUsed / 1024 / 1024)} MB`
    },
    cpu: cpuUsage,
    uptime: process.uptime()
  });
});

2. Graceful Shutdown:
process.on('SIGTERM', gracefulShutdown);
process.on('SIGINT', gracefulShutdown);

function gracefulShutdown(signal) {
  console.log(`Received ${signal}. Graceful shutdown...`);
  
  server.close(() => {
    console.log('HTTP server closed.');
    
    // Close database connections
    database.close(() => {
      console.log('Database connections closed.');
      process.exit(0);
    });
  });
}

Key Differences: Node.js vs Browser JavaScript:

Node.js (Server-side):
   - Can handle thousands of concurrent connections
   - Uses libuv for I/O operations
   - Has access to file system and network directly
   - Memory and CPU resources are server-limited

Browser JavaScript:
   - Limited by browser connection limits (6-8 per domain)
   - Uses Web APIs for I/O operations
   - Sandboxed environment with security restrictions
   - Memory and CPU resources are client-limited

Summary:
Node.js Express handles 1000 API requests efficiently through:
   - Event-driven, non-blocking I/O architecture
   - Single-threaded event loop with background thread pool
   - Efficient memory management and connection pooling
   - Clustering for CPU-intensive operations
   - Caching and rate limiting for optimization
   - Streaming for large data responses

The key advantage is that Node.js doesn't create a new thread for each request, instead it uses an event loop to manage all requests efficiently with minimal memory overhead.

Context Questions:

1. "What's the difference between Node.js clustering and load balancing?"
2. "How do you handle memory leaks in high-concurrency Node.js applications?"
3. "What are the trade-offs between connection pooling and connection per request?"
4. "How do you implement circuit breakers in Express.js for fault tolerance?"
5. "What's the difference between libuv thread pool and worker threads in Node.js?"
6. "How do you monitor and debug performance issues in production Express apps?"
7. "What are the best practices for handling graceful shutdowns in Node.js applications?"
8. "How do you implement request queuing and backpressure in Express.js?"
9. "What's the difference between streaming and buffering for large responses?"
10. "How do you handle database connection limits in high-concurrency scenarios?"

---

Additional Context Questions for Deep Dive:

Performance & Scalability:

1. "How do you implement horizontal scaling for Node.js applications?"
2. "What are the memory management strategies for long-running Node.js processes?"
3. "How do you handle CPU-intensive tasks without blocking the event loop?"
4. "What are the best practices for database optimization in Node.js applications?"

Architecture & Design:

1. "How do you design microservices architecture with Node.js and Express?"
2. "What are the patterns for handling distributed transactions in Node.js?"
3. "How do you implement service discovery and load balancing?"
4. "What are the best practices for API versioning and backward compatibility?"

Monitoring & Debugging:

1. "How do you implement comprehensive logging and monitoring in Node.js?"
2. "What are the tools and techniques for performance profiling?"
3. "How do you handle error tracking and alerting in production?"
4. "What are the best practices for debugging memory leaks and performance issues?"
