JavaScript Interview Questions & Answers

--------------------------------------------------------------------------------

2. If JS is Async, How to Make it Sync and Why?

Question: If JS is async how make it sync and why?

Answer:
JavaScript is single-threaded but supports asynchronous operations. Sometimes we need to make async operations behave synchronously.

-> Methods to Make Async Code Synchronous:

-> 1. Using `async/await` (Recommended):
```javascript
// Async function
async function fetchData() {
  try {
    const response = await fetch('https://api.example.com/data');
    const data = await response.json();
    return data;
  } catch (error) {
    console.error('Error:', error);
  }
}

// Usage
async function main() {
  const result = await fetchData(); // Waits for completion
  console.log(result); // Executes after fetchData completes
}
```

-> 2. Using Promises with `.then()`:
```javascript
function fetchDataSync() {
  return fetch('https://api.example.com/data')
    .then(response => response.json())
    .then(data => {
      console.log(data);
      return data;
    })
    .catch(error => console.error('Error:', error));
}
```

-> 3. Using `Promise.all()` for Multiple Operations:
```javascript
async function fetchMultipleData() {
  const [users, posts, comments] = await Promise.all([
    fetch('/api/users').then(r => r.json()),
    fetch('/api/posts').then(r => r.json()),
    fetch('/api/comments').then(r => r.json())
  ]);
  
  return { users, posts, comments };
}
```

-> 4. Sequential Processing with `for...of`:
```javascript
async function processSequentially(urls) {
  const results = [];
  
  for (const url of urls) {
    const response = await fetch(url);
    const data = await response.json();
    results.push(data);
  }
  
  return results;
}
```

-> Why Make Async Code Synchronous?

-> 1. Data Dependencies:
   -> When subsequent operations depend on previous results
   -> Example: Need user ID before fetching user posts

-> 2. Sequential Processing:
   -> Processing items one by one in order
   -> Rate limiting API calls

-> 3. Error Handling:
   -> Easier error handling and debugging
   -> Clear execution flow

-> 4. Business Logic Requirements:
   -> Payment processing must complete before order confirmation
   -> Authentication before accessing protected resources

-> Important Notes:
   -> `async/await` doesn't make JavaScript truly synchronous
   -> It makes asynchronous code appear synchronous
   -> The event loop continues running
   -> Non-blocking for other operations

--------------------------------------------------------------------------------

3. How JS Handles 1000 API Requests Simultaneously?

Question: How JS handles 1000 API requests in same time as one request since it is single threaded and though event loop but still in one time one thing is being executed?

Answer:
This is an excellent question about JavaScript's concurrency model. JavaScript handles multiple API requests efficiently despite being single-threaded through the Event Loop and Web APIs.

-> How It Works:

-> 1. Single-Threaded Main Thread:
   -> JavaScript execution happens on one main thread
   -> Only one piece of JavaScript code executes at a time
   -> But I/O operations (like API calls) are non-blocking

-> 2. Web APIs & Browser Environment:
```javascript
// When you make 1000 API calls:
const promises = [];
for (let i = 0; i < 1000; i++) {
  promises.push(fetch(`https://api.example.com/data/${i}`));
}

// All 1000 requests are initiated immediately
Promise.all(promises)
  .then(responses => {
    console.log('All 1000 requests completed!');
  });
```

-> 3. The Process Breakdown:

-> Step 1: Request Initiation (Synchronous)
```javascript
// Main thread executes this synchronously
fetch('https://api.example.com/data/1'); // Request 1 initiated
fetch('https://api.example.com/data/2'); // Request 2 initiated
fetch('https://api.example.com/data/3'); // Request 3 initiated
// ... 1000 requests initiated rapidly
```

-> Step 2: Delegation to Web APIs
   -> Each `fetch()` call is immediately handed off to browser's Web APIs
   -> Network requests are handled by the browser's networking layer
   -> Main JavaScript thread continues executing (non-blocking)

-> Step 3: Concurrent Network Operations
   -> Browser can handle multiple network connections simultaneously
   -> Typical browsers support 6-8 concurrent connections per domain
   -> Requests are queued and processed as connections become available

-> Step 4: Event Loop & Callback Queue
```javascript
// As responses arrive, callbacks are queued
fetch('https://api.example.com/data/1')
  .then(response => {
    // This callback goes to microtask queue when response arrives
    console.log('Request 1 completed');
  });
```

-> Visual Representation:

```
Main Thread:          Web APIs:              Event Loop:
┌─────────────┐      ┌──────────────┐       ┌─────────────┐
│ fetch(url1) │────→ │ HTTP Request │       │ Callback    │
│ fetch(url2) │────→ │ HTTP Request │       │ Queue       │
│ fetch(url3) │────→ │ HTTP Request │       │             │
│     ...     │      │     ...      │       │ ┌─────────┐ │
│fetch(url1000)│──→  │ HTTP Request │       │ │Response1││
└─────────────┘      └──────────────┘       │ │Response2││
                                            │ │Response3││
                                            │ │   ...   ││
                                            │ └─────────┘ │
                                            └─────────────┘
```

-> Key Points:

-> 1. Concurrency vs Parallelism:
   -> JavaScript: Concurrent (appears simultaneous)
   -> Network layer: Parallel (actually simultaneous)

-> 2. Browser Limitations:
```javascript
// Browser limits concurrent connections
// Typically 6-8 per domain, 256 total across all domains
const batchSize = 6;
const batches = [];

for (let i = 0; i < 1000; i += batchSize) {
  batches.push(urls.slice(i, i + batchSize));
}

// Process in batches to respect browser limits
for (const batch of batches) {
  await Promise.all(batch.map(url => fetch(url)));
}
```

-> 3. Memory and Performance Considerations:
```javascript
// For 1000 requests, consider streaming or pagination
async function fetchInBatches(urls, batchSize = 10) {
  const results = [];
  
  for (let i = 0; i < urls.length; i += batchSize) {
    const batch = urls.slice(i, i + batchSize);
    const batchResults = await Promise.all(
      batch.map(url => fetch(url).then(r => r.json()))
    );
    results.push(...batchResults);
    
    // Optional: Add delay to prevent overwhelming the server
    await new Promise(resolve => setTimeout(resolve, 100));
  }
  
  return results;
}
```

-> 4. Error Handling for Multiple Requests:
```javascript
async function fetchWithErrorHandling(urls) {
  const results = await Promise.allSettled(
    urls.map(async url => {
      try {
        const response = await fetch(url);
        return await response.json();
      } catch (error) {
        return { error: error.message, url };
      }
    })
  );
  
  const successful = results.filter(r => r.status === 'fulfilled');
  const failed = results.filter(r => r.status === 'rejected');
  
  return { successful, failed };
}
```

-> Summary:
JavaScript can handle 1000 API requests "simultaneously" because:
   -> Request initiation is fast and non-blocking
   -> Network operations are handled by browser Web APIs (outside main thread)
   -> Event loop efficiently manages response callbacks
   -> Browser networking layer handles actual parallel connections
   -> Main thread remains free to process responses as they arrive

The key insight is that JavaScript delegates I/O operations to the browser environment, allowing the single thread to remain responsive while multiple network operations happen concurrently.

--------------------------------------------------------------------------------

4. How Node.js Express Handles 1000 API Requests?

Question: How does Node.js Express receive and execute and send back 1000 API requests?

Answer:
Node.js Express can handle thousands of concurrent API requests efficiently through its event-driven, non-blocking I/O architecture. Here's how it works:

-> Node.js Architecture for Handling Multiple Requests:

-> 1. Event Loop (Single Thread):
   -> Main thread runs the event loop
   -> Handles I/O operations asynchronously
   -> Delegates CPU-intensive tasks to thread pool
   -> Non-blocking by design

-> 2. libuv Thread Pool:
   -> Background thread pool (default 4 threads)
   -> Handles file system operations, DNS lookups, some crypto operations
   -> CPU-intensive tasks are offloaded here

-> 3. V8 Engine:
   -> Executes JavaScript code
   -> Optimizes code execution
   -> Manages memory and garbage collection

-> How Express Handles 1000 Concurrent Requests:

-> Step 1: Request Reception
```javascript
const express = require('express');
const app = express();

// This endpoint can handle thousands of concurrent requests
app.get('/api/data/:id', async (req, res) => {
  try {
    // Non-blocking database call
    const data = await database.findById(req.params.id);
    res.json(data);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.listen(3000, () => {
  console.log('Server running on port 3000');
});
```

-> Step 2: Event Loop Processing
```javascript
// When 1000 requests hit simultaneously:
// 1. Each request creates an event in the event queue
// 2. Event loop processes them one by one (very fast)
// 3. I/O operations (DB calls, API calls) are non-blocking
// 4. Callbacks are queued when I/O completes

// Example of non-blocking operations:
app.get('/api/users', async (req, res) => {
  // These operations don't block the event loop
  const [users, posts, comments] = await Promise.all([
    database.getUsers(),     // Non-blocking DB call
    database.getPosts(),     // Non-blocking DB call  
    database.getComments()   // Non-blocking DB call
  ]);
  
  res.json({ users, posts, comments });
});
```

-> Step 3: Concurrent Processing Example
```javascript
const express = require('express');
const app = express();

// Simulate handling 1000 requests
app.get('/api/process/:id', async (req, res) => {
  const startTime = Date.now();
  
  // Simulate async work (database query, API call, etc.)
  await new Promise(resolve => setTimeout(resolve, 100));
  
  const processingTime = Date.now() - startTime;
  
  res.json({
    id: req.params.id,
    processingTime,
    timestamp: new Date().toISOString(),
    message: `Request ${req.params.id} processed successfully`
  });
});

// Load testing script to send 1000 requests
async function loadTest() {
  const promises = [];
  
  for (let i = 1; i <= 1000; i++) {
    promises.push(
      fetch(`http://localhost:3000/api/process/${i}`)
        .then(res => res.json())
    );
  }
  
  const results = await Promise.all(promises);
  console.log(`Processed ${results.length} requests successfully`);
}
```

-> Performance Optimizations for High Concurrency:

-> 1. Connection Pooling:
```javascript
const mysql = require('mysql2/promise');

// Create connection pool to handle multiple DB connections
const pool = mysql.createPool({
  host: 'localhost',
  user: 'user',
  password: 'password',
  database: 'mydb',
  waitForConnections: true,
  connectionLimit: 10,        // Max 10 concurrent connections
  queueLimit: 0
});

app.get('/api/users', async (req, res) => {
  try {
    const [rows] = await pool.execute('SELECT * FROM users');
    res.json(rows);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
```

-> 2. Clustering for CPU-Intensive Tasks:
```javascript
const cluster = require('cluster');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
  console.log(`Master ${process.pid} is running`);
  
  // Fork workers equal to CPU cores
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }
  
  cluster.on('exit', (worker, code, signal) => {
    console.log(`Worker ${worker.process.pid} died`);
    cluster.fork(); // Restart worker
  });
} else {
  // Workers can share any TCP port
  const app = express();
  
  app.get('/api/cpu-intensive', (req, res) => {
    // CPU-intensive operation
    let result = 0;
    for (let i = 0; i < 1000000; i++) {
      result += Math.random();
    }
    res.json({ result, worker: process.pid });
  });
  
  app.listen(3000, () => {
    console.log(`Worker ${process.pid} started`);
  });
}
```

-> 3. Caching for Frequently Accessed Data:
```javascript
const NodeCache = require('node-cache');
const cache = new NodeCache({ stdTTL: 600 }); // 10 minutes TTL

app.get('/api/cached-data/:id', async (req, res) => {
  const { id } = req.params;
  
  // Check cache first
  const cachedData = cache.get(`data_${id}`);
  if (cachedData) {
    return res.json({ data: cachedData, fromCache: true });
  }
  
  // Fetch from database if not cached
  const data = await database.findById(id);
  
  // Store in cache
  cache.set(`data_${id}`, data);
  
  res.json({ data, fromCache: false });
});
```

-> 4. Request Rate Limiting:
```javascript
const rateLimit = require('express-rate-limit');

// Limit each IP to 100 requests per 15 minutes
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100, // limit each IP to 100 requests per windowMs
  message: 'Too many requests from this IP'
});

app.use('/api/', limiter);
```

-> 5. Streaming for Large Responses:
```javascript
const fs = require('fs');

app.get('/api/large-data', (req, res) => {
  res.setHeader('Content-Type', 'application/json');
  
  // Stream large data instead of loading into memory
  const readStream = fs.createReadStream('large-data.json');
  readStream.pipe(res);
});
```

-> Memory Management for High Concurrency:

-> 1. Monitoring Memory Usage:
```javascript
app.get('/api/health', (req, res) => {
  const memoryUsage = process.memoryUsage();
  const cpuUsage = process.cpuUsage();
  
  res.json({
    memory: {
      rss: `${Math.round(memoryUsage.rss / 1024 / 1024)} MB`,
      heapTotal: `${Math.round(memoryUsage.heapTotal / 1024 / 1024)} MB`,
      heapUsed: `${Math.round(memoryUsage.heapUsed / 1024 / 1024)} MB`
    },
    cpu: cpuUsage,
    uptime: process.uptime()
  });
});
```

-> 2. Graceful Shutdown:
```javascript
process.on('SIGTERM', gracefulShutdown);
process.on('SIGINT', gracefulShutdown);

function gracefulShutdown(signal) {
  console.log(`Received ${signal}. Graceful shutdown...`);
  
  server.close(() => {
    console.log('HTTP server closed.');
    
    // Close database connections
    database.close(() => {
      console.log('Database connections closed.');
      process.exit(0);
    });
  });
}
```

-> Key Differences: Node.js vs Browser JavaScript:

-> Node.js (Server-side):
   -> Can handle thousands of concurrent connections
   -> Uses libuv for I/O operations
   -> Has access to file system and network directly
   -> Memory and CPU resources are server-limited

-> Browser JavaScript:
   -> Limited by browser connection limits (6-8 per domain)
   -> Uses Web APIs for I/O operations
   -> Sandboxed environment with security restrictions
   -> Memory and CPU resources are client-limited

-> Summary:
Node.js Express handles 1000 API requests efficiently through:
   -> Event-driven, non-blocking I/O architecture
   -> Single-threaded event loop with background thread pool
   -> Efficient memory management and connection pooling
   -> Clustering for CPU-intensive operations
   -> Caching and rate limiting for optimization
   -> Streaming for large data responses

The key advantage is that Node.js doesn't create a new thread for each request, instead it uses an event loop to manage all requests efficiently with minimal memory overhead. 